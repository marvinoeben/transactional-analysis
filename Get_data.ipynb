{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download, parse and cleanse the data\n",
    "In this notebook, we download, check, parse and cleanse the dataset.  \n",
    "Also, we translate several values and column names to their English counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the data checking variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "if not os.path.exists(\"Downloads\"):\n",
    "    os.makedirs(\"Downloads\")\n",
    "if not os.path.isfile(\"Downloads/data_berka.zip\"):    \n",
    "    zipfiles = urllib.URLopener()\n",
    "    zipfiles.retrieve(\"http://lisp.vse.cz/pkdd99/DATA/data_berka.zip\", \"Downloads/data_berka.zip\")\n",
    "if not os.path.isfile(\"Downloads/berka.htm\"):    \n",
    "    challenge_file = urllib.URLopener()\n",
    "    challenge_file.retrieve(\"http://lisp.vse.cz/pkdd99/Challenge/berka.htm\", \"Downloads/berka.htm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "    \n",
    "zip_ref = zipfile.ZipFile('Downloads/data_berka.zip', 'r')\n",
    "zip_ref.extractall('data')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the first two lines for every file\n",
    "Inspect filetype, seperator and column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('data')\n",
    "if check:\n",
    "    for fl in files:\n",
    "        with open('data/' + fl) as myfile:\n",
    "            print fl\n",
    "            lines = myfile.readlines()[0:2]\n",
    "            print '\\t' + repr(lines[0])\n",
    "            print '\\t' + repr(lines[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load into pandas data.frames:\n",
    "Dataframes will be imported into a dictionary for quick scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moeben001/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_dict = {}\n",
    "keys = [fl.split('.')[0] for fl in files]\n",
    "\n",
    "for fl, key in zip(files,keys):\n",
    "    if key==\"trans\":\n",
    "        data_dict[key] = pd.read_csv('data/' + fl, sep = ';', \n",
    "                                     quotechar = '\\\"',\n",
    "                                     dtype = {'account':np.float64})\n",
    "    else:\n",
    "        data_dict[key] = pd.read_csv('data/' + fl, sep = ';', quotechar = '\\\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if check:\n",
    "    for key in keys:\n",
    "        print key\n",
    "        print 'Shape: ' + str(data_dict[key].shape)\n",
    "        print 'First_row:' \n",
    "        print data_dict[key].iloc[0]\n",
    "        print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### District headers are not directly usefull.\n",
    "Print the explanation file;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if check:\n",
    "    from IPython.core.display import HTML\n",
    "    html_file = open('Downloads/berka.htm').read()\n",
    "    HTML(html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains a mapping. Set manually (Scraping is a waste of time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_headers = ['district_id', 'district_name', 'region', \n",
    "               'inhabitants', 'municipalties_499_less', \n",
    "               'municipalties_500_1999', 'municipalties_2000_9999', \n",
    "               'municipalties_10000_more', 'cities','urban_ratio',\n",
    "               'avg_salary', 'unemployment_rate_1995', \n",
    "               'unemployment_rate_1996', 'entrepeneurs_per_1000', \n",
    "               'commited_crimes_1995','comitted_crimes_1996']\n",
    "data_dict['district'].columns = new_headers\n",
    "if check:\n",
    "    data_dict['district'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleansing (according to description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set dates to a date format\n",
    "data_dict['account']['date'] = pd.to_datetime(data_dict['account']['date'], format='%y%m%d')\n",
    "data_dict['card']['issued'] = pd.to_datetime(data_dict['card']['issued'], \n",
    "                                             format='%y%m%d %H:%M:%S')\n",
    "data_dict['trans']['date'] = pd.to_datetime(data_dict['trans']['date'], format='%y%m%d')\n",
    "data_dict['loan']['date'] = pd.to_datetime(data_dict['loan']['date'], format='%y%m%d')\n",
    "\n",
    "# Client needs modification (seperate the sexes and adjust the dates)\n",
    "data_dict['client']['sex'] = \"M\"\n",
    "tmp = (data_dict['client']['birth_number']/100).round().astype(int)\n",
    "tmp = tmp % 100 > 50\n",
    "data_dict['client'].loc[tmp, \"sex\"] = \"F\"\n",
    "data_dict['client'].loc[tmp, \"birth_number\"] = data_dict['client'].loc[tmp, \"birth_number\"] - 5000\n",
    "\n",
    "# Assumption: Everyone borne in the 1900's, (min birth_number -> 110820, max -> 870927)\n",
    "# 113 is rather old.\n",
    "data_dict['client']['birth_number'] = data_dict['client']['birth_number'] + 19000000\n",
    "data_dict['client']['birth_number'] = pd.to_datetime(data_dict['client']['birth_number'], \n",
    "                                                format='%Y%m%d')\n",
    "\n",
    "if check:\n",
    "    print data_dict['account']['date'].describe()\n",
    "    print data_dict['card']['issued'].describe()\n",
    "    print data_dict['trans']['date'].describe()\n",
    "    print data_dict['loan']['date'].describe()\n",
    "    print data_dict['client']['birth_number'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change data to its English equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the account data:\n",
    "df = data_dict['account']\n",
    "df.loc[df.frequency == 'POPLATEK MESICNE', 'frequency'] = 'monthly'\n",
    "df.loc[df.frequency == 'POPLATEK TYDNE', 'frequency'] = 'weekly'\n",
    "df.loc[df.frequency == 'POPLATEK PO OBRATU', 'frequency'] = 'after_transaction'\n",
    "\n",
    "data_dict['account'] = df\n",
    "\n",
    "# For the order data:\n",
    "df = data_dict['order']\n",
    "df.loc[df.k_symbol == 'POJISTNE', 'k_symbol'] = 'insurance'\n",
    "df.loc[df.k_symbol == 'SIPO', 'k_symbol'] = 'household'\n",
    "df.loc[df.k_symbol == 'LEASING', 'k_symbol'] = 'leasing'\n",
    "df.loc[df.k_symbol == 'UVER', 'k_symbol'] = 'loan'\n",
    "\n",
    "data_dict['order'] = df\n",
    "\n",
    "# For the transaction data:\n",
    "df = data_dict['trans']\n",
    "df.loc[df.type == 'PRIJEM', 'type'] = 'credit'\n",
    "df.loc[df.type == 'VYDAJ', 'type'] = 'withdrawal'\n",
    "df.loc[df.operation == 'VYBER KARTOU', 'operation'] = 'cc_withdrawal'\n",
    "df.loc[df.operation == 'VKLAD', 'operation'] = 'cash_credit'\n",
    "df.loc[df.operation == 'PREVOD Z UCTU', 'operation'] = 'inc_bank'\n",
    "df.loc[df.operation == 'VYBER', 'operation'] = 'cash_withdrawl'\n",
    "df.loc[df.operation == 'PREVOD NA UCET', 'operation'] = 'outg_bank'\n",
    "df.loc[df.k_symbol == 'POJISTNE', 'k_symbol'] = 'insurance'\n",
    "df.loc[df.k_symbol == 'SLUZBY', 'k_symbol'] = 'payment_statement'\n",
    "df.loc[df.k_symbol == 'UROK', 'k_symbol'] = 'interest_credited'\n",
    "df.loc[df.k_symbol == 'SANKC. UROK', 'k_symbol'] = 'interest_sactioned'\n",
    "df.loc[df.k_symbol == 'SIPO', 'k_symbol'] = 'household'\n",
    "df.loc[df.k_symbol == 'DUCHOD', 'k_symbol'] = 'pension'\n",
    "df.loc[df.k_symbol == 'UVER', 'k_symbol'] = 'loan'\n",
    "data_dict['trans'] = df\n",
    "\n",
    "# For the loan data:\n",
    "df = data_dict['loan']\n",
    "df.loc[df.status == 'A', 'status'] = 'fin_no_problem'\n",
    "df.loc[df.status == 'B', 'status'] = 'fin_unpaid'\n",
    "df.loc[df.status == 'C', 'status'] = 'run_no_problem'\n",
    "df.loc[df.status == 'D', 'status'] = 'run_but_debt'\n",
    "data_dict['loan'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge data into three data.frames, client info, demographic info and transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add disposition\n",
    "client_info = pd.merge(left = data_dict['client'], \n",
    "                       right = data_dict['disp'], \n",
    "                       how ='left', \n",
    "                       on = 'client_id')\n",
    "# Add account info\n",
    "client_info = pd.merge(left = client_info, \n",
    "                       right = data_dict['account'], \n",
    "                       how ='left', \n",
    "                       on = 'account_id',\n",
    "                       suffixes=('_client', '_branch'))\n",
    "\n",
    "# Add Loans\n",
    "client_info = pd.merge(left = client_info, \n",
    "                       right = data_dict['loan'], \n",
    "                       how ='left', \n",
    "                       on = 'account_id',\n",
    "                       suffixes=('_client', '_loan'))\n",
    "# Add credit cards\n",
    "client_info = pd.merge(left = client_info, \n",
    "                       right = data_dict['card'], \n",
    "                       how ='left', \n",
    "                       on = 'disp_id',\n",
    "                       suffixes=('_client', '_card'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demographic_info = data_dict['district']\n",
    "transaction_info = data_dict['trans']\n",
    "order_info = data_dict['order']\n",
    "\n",
    "client_info.to_csv('data/client_info.csv')\n",
    "demographic_info.to_csv('data/demographic_data.csv')\n",
    "transaction_info.to_csv('data/transction_info.csv')\n",
    "order_info.to_csv('data/order_info.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
